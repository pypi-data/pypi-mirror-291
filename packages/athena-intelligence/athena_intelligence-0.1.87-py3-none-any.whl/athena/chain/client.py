# This file was auto-generated by Fern from our API Definition.

import typing
import urllib.parse
from json.decoder import JSONDecodeError

from ..core.api_error import ApiError
from ..core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from ..core.jsonable_encoder import jsonable_encoder
from ..core.pydantic_utilities import pydantic_v1
from ..core.query_encoder import encode_query
from ..core.remove_none_from_dict import remove_none_from_dict
from ..core.request_options import RequestOptions
from ..errors.unprocessable_entity_error import UnprocessableEntityError
from ..types.document import Document
from ..types.http_validation_error import HttpValidationError
from ..types.llm_model import LlmModel
from ..types.map_reduce_chain_out import MapReduceChainOut
from ..types.structured_parse_result import StructuredParseResult

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class ChainClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._client_wrapper = client_wrapper

    def structured_parse(
        self,
        *,
        text_input: str,
        custom_type_dict: typing.Dict[str, typing.Any],
        model: LlmModel,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> StructuredParseResult:
        """
        Parameters
        ----------
        text_input : str
            The text input to be parsed.

        custom_type_dict : typing.Dict[str, typing.Any]
            A dictionary of field names and their default values.

        model : LlmModel

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        StructuredParseResult
            Successful Response

        Examples
        --------
        from athena import LlmModel
        from athena.client import Athena

        client = Athena(
            api_key="YOUR_API_KEY",
        )
        client.chain.structured_parse(
            text_input='Athena is an AI-native analytics platform and artificial employee built to accelerate analytics workflows\n                by offering enterprise teams co-pilot and auto-pilot modes. Athena learns your workflow as a co-pilot,\n                allowing you to hand over controls to her for autonomous execution with confidence."\n\n                Give me all of the modes Athena provides.',
            custom_type_dict={},
            model=LlmModel.GPT_4_TURBO,
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            method="POST",
            url=urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v0/structured-parse"),
            params=encode_query(
                jsonable_encoder(
                    request_options.get("additional_query_parameters") if request_options is not None else None
                )
            ),
            json=jsonable_encoder({"text_input": text_input, "custom_type_dict": custom_type_dict, "model": model})
            if request_options is None or request_options.get("additional_body_parameters") is None
            else {
                **jsonable_encoder({"text_input": text_input, "custom_type_dict": custom_type_dict, "model": model}),
                **(jsonable_encoder(remove_none_from_dict(request_options.get("additional_body_parameters", {})))),
            },
            headers=jsonable_encoder(
                remove_none_from_dict(
                    {
                        **self._client_wrapper.get_headers(),
                        **(request_options.get("additional_headers", {}) if request_options is not None else {}),
                    }
                )
            ),
            timeout=request_options.get("timeout_in_seconds")
            if request_options is not None and request_options.get("timeout_in_seconds") is not None
            else self._client_wrapper.get_timeout(),
            retries=0,
            max_retries=request_options.get("max_retries") if request_options is not None else 0,  # type: ignore
        )
        if 200 <= _response.status_code < 300:
            return pydantic_v1.parse_obj_as(StructuredParseResult, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(
                pydantic_v1.parse_obj_as(HttpValidationError, _response.json())  # type: ignore
            )
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def map_reduce_chain(
        self,
        *,
        documents: typing.Sequence[Document],
        model: LlmModel,
        operator_prompt: str,
        reducer_prompt: str,
        input: str,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> MapReduceChainOut:
        """
        Parameters
        ----------
        documents : typing.Sequence[Document]

        model : LlmModel

        operator_prompt : str

        reducer_prompt : str

        input : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        MapReduceChainOut
            Successful Response

        Examples
        --------
        from athena import Document, LlmModel
        from athena.client import Athena

        client = Athena(
            api_key="YOUR_API_KEY",
        )
        client.chain.map_reduce_chain(
            documents=[
                Document(
                    page_content="Athena is an AI-native analytics platform and artificial employee built to accelerate analytics workflows by offering enterprise teams co-pilot and auto-pilot modes. Athena learns your workflow as a co-pilot, allowing you to hand over controls to her for autonomous execution with confidence.",
                    metadata={"key": "value"},
                )
            ],
            model=LlmModel.MISTRAL_LARGE_0224,
            operator_prompt="summarize the content",
            reducer_prompt="Combine these summaries",
            input="return a summary in a single sentence",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            method="POST",
            url=urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v0/tools/map-reduce"),
            params=encode_query(
                jsonable_encoder(
                    request_options.get("additional_query_parameters") if request_options is not None else None
                )
            ),
            json=jsonable_encoder(
                {
                    "documents": documents,
                    "model": model,
                    "operator_prompt": operator_prompt,
                    "reducer_prompt": reducer_prompt,
                    "input": input,
                }
            )
            if request_options is None or request_options.get("additional_body_parameters") is None
            else {
                **jsonable_encoder(
                    {
                        "documents": documents,
                        "model": model,
                        "operator_prompt": operator_prompt,
                        "reducer_prompt": reducer_prompt,
                        "input": input,
                    }
                ),
                **(jsonable_encoder(remove_none_from_dict(request_options.get("additional_body_parameters", {})))),
            },
            headers=jsonable_encoder(
                remove_none_from_dict(
                    {
                        **self._client_wrapper.get_headers(),
                        **(request_options.get("additional_headers", {}) if request_options is not None else {}),
                    }
                )
            ),
            timeout=request_options.get("timeout_in_seconds")
            if request_options is not None and request_options.get("timeout_in_seconds") is not None
            else self._client_wrapper.get_timeout(),
            retries=0,
            max_retries=request_options.get("max_retries") if request_options is not None else 0,  # type: ignore
        )
        if 200 <= _response.status_code < 300:
            return pydantic_v1.parse_obj_as(MapReduceChainOut, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(
                pydantic_v1.parse_obj_as(HttpValidationError, _response.json())  # type: ignore
            )
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)


class AsyncChainClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._client_wrapper = client_wrapper

    async def structured_parse(
        self,
        *,
        text_input: str,
        custom_type_dict: typing.Dict[str, typing.Any],
        model: LlmModel,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> StructuredParseResult:
        """
        Parameters
        ----------
        text_input : str
            The text input to be parsed.

        custom_type_dict : typing.Dict[str, typing.Any]
            A dictionary of field names and their default values.

        model : LlmModel

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        StructuredParseResult
            Successful Response

        Examples
        --------
        from athena import LlmModel
        from athena.client import AsyncAthena

        client = AsyncAthena(
            api_key="YOUR_API_KEY",
        )
        await client.chain.structured_parse(
            text_input='Athena is an AI-native analytics platform and artificial employee built to accelerate analytics workflows\n                by offering enterprise teams co-pilot and auto-pilot modes. Athena learns your workflow as a co-pilot,\n                allowing you to hand over controls to her for autonomous execution with confidence."\n\n                Give me all of the modes Athena provides.',
            custom_type_dict={},
            model=LlmModel.GPT_4_TURBO,
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            method="POST",
            url=urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v0/structured-parse"),
            params=encode_query(
                jsonable_encoder(
                    request_options.get("additional_query_parameters") if request_options is not None else None
                )
            ),
            json=jsonable_encoder({"text_input": text_input, "custom_type_dict": custom_type_dict, "model": model})
            if request_options is None or request_options.get("additional_body_parameters") is None
            else {
                **jsonable_encoder({"text_input": text_input, "custom_type_dict": custom_type_dict, "model": model}),
                **(jsonable_encoder(remove_none_from_dict(request_options.get("additional_body_parameters", {})))),
            },
            headers=jsonable_encoder(
                remove_none_from_dict(
                    {
                        **self._client_wrapper.get_headers(),
                        **(request_options.get("additional_headers", {}) if request_options is not None else {}),
                    }
                )
            ),
            timeout=request_options.get("timeout_in_seconds")
            if request_options is not None and request_options.get("timeout_in_seconds") is not None
            else self._client_wrapper.get_timeout(),
            retries=0,
            max_retries=request_options.get("max_retries") if request_options is not None else 0,  # type: ignore
        )
        if 200 <= _response.status_code < 300:
            return pydantic_v1.parse_obj_as(StructuredParseResult, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(
                pydantic_v1.parse_obj_as(HttpValidationError, _response.json())  # type: ignore
            )
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def map_reduce_chain(
        self,
        *,
        documents: typing.Sequence[Document],
        model: LlmModel,
        operator_prompt: str,
        reducer_prompt: str,
        input: str,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> MapReduceChainOut:
        """
        Parameters
        ----------
        documents : typing.Sequence[Document]

        model : LlmModel

        operator_prompt : str

        reducer_prompt : str

        input : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        MapReduceChainOut
            Successful Response

        Examples
        --------
        from athena import Document, LlmModel
        from athena.client import AsyncAthena

        client = AsyncAthena(
            api_key="YOUR_API_KEY",
        )
        await client.chain.map_reduce_chain(
            documents=[
                Document(
                    page_content="Athena is an AI-native analytics platform and artificial employee built to accelerate analytics workflows by offering enterprise teams co-pilot and auto-pilot modes. Athena learns your workflow as a co-pilot, allowing you to hand over controls to her for autonomous execution with confidence.",
                    metadata={"key": "value"},
                )
            ],
            model=LlmModel.MISTRAL_LARGE_0224,
            operator_prompt="summarize the content",
            reducer_prompt="Combine these summaries",
            input="return a summary in a single sentence",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            method="POST",
            url=urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v0/tools/map-reduce"),
            params=encode_query(
                jsonable_encoder(
                    request_options.get("additional_query_parameters") if request_options is not None else None
                )
            ),
            json=jsonable_encoder(
                {
                    "documents": documents,
                    "model": model,
                    "operator_prompt": operator_prompt,
                    "reducer_prompt": reducer_prompt,
                    "input": input,
                }
            )
            if request_options is None or request_options.get("additional_body_parameters") is None
            else {
                **jsonable_encoder(
                    {
                        "documents": documents,
                        "model": model,
                        "operator_prompt": operator_prompt,
                        "reducer_prompt": reducer_prompt,
                        "input": input,
                    }
                ),
                **(jsonable_encoder(remove_none_from_dict(request_options.get("additional_body_parameters", {})))),
            },
            headers=jsonable_encoder(
                remove_none_from_dict(
                    {
                        **self._client_wrapper.get_headers(),
                        **(request_options.get("additional_headers", {}) if request_options is not None else {}),
                    }
                )
            ),
            timeout=request_options.get("timeout_in_seconds")
            if request_options is not None and request_options.get("timeout_in_seconds") is not None
            else self._client_wrapper.get_timeout(),
            retries=0,
            max_retries=request_options.get("max_retries") if request_options is not None else 0,  # type: ignore
        )
        if 200 <= _response.status_code < 300:
            return pydantic_v1.parse_obj_as(MapReduceChainOut, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(
                pydantic_v1.parse_obj_as(HttpValidationError, _response.json())  # type: ignore
            )
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)
