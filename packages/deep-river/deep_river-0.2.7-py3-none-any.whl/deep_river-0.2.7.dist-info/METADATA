Metadata-Version: 2.1
Name: deep_river
Version: 0.2.7
Summary: Online Deep Learning for river
Home-page: https://online-ml.github.io/deep-river/
Author: Cedric Kulbach
Author-email: cedric.kulbach@googlemail.com
License: BSD-3
Classifier: License :: OSI Approved :: BSD License
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: Implementation :: CPython
Classifier: Programming Language :: Python :: Implementation :: PyPy
Requires-Python: >=3.6.0
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: scikit-learn~=1.5.0
Requires-Dist: torch~=2.2.2
Requires-Dist: pandas~=2.2.2
Requires-Dist: numpy~=1.26.4
Requires-Dist: river~=0.21.2
Requires-Dist: scipy~=1.13.0
Requires-Dist: tqdm~=4.66.5
Requires-Dist: ordered-set~=4.1.0
Requires-Dist: torchviz~=0.0.2
Requires-Dist: dataclasses; python_version == "3.6"
Provides-Extra: all
Requires-Dist: graphviz>=0.20.3; extra == "all"
Requires-Dist: matplotlib>=3.9.2; extra == "all"
Requires-Dist: mypy>=1.11.1; extra == "all"
Requires-Dist: pre-commit>=3.8.0; extra == "all"
Requires-Dist: pytest>=8.3.2; extra == "all"
Requires-Dist: pytest-cov>=5.0.0; extra == "all"
Requires-Dist: black>=24.8.0; extra == "all"
Requires-Dist: flake8>=7.1.1; extra == "all"
Requires-Dist: isort>=5.13.2; extra == "all"
Requires-Dist: jupyter>=1.0.0; extra == "all"
Requires-Dist: pyupgrade==3.17.0; extra == "all"
Requires-Dist: flask>=2.0.2; extra == "all"
Requires-Dist: ipykernel>=6.9.0; extra == "all"
Requires-Dist: mike>=0.5.3; extra == "all"
Requires-Dist: mkdocs>=1.2.3; extra == "all"
Requires-Dist: mkdocs-awesome-pages-plugin>=2.7.0; extra == "all"
Requires-Dist: mkdocs-gen-files>=0.3.5; extra == "all"
Requires-Dist: mkdocs-charts-plugin>=0.0.8; extra == "all"
Requires-Dist: mkdocs-literate-nav>=0.4.1; extra == "all"
Requires-Dist: mkdocs-material>=8.1.11; extra == "all"
Requires-Dist: mkdocstrings[python]>=0.19.0; extra == "all"
Requires-Dist: pytkdocs[numpy-style]>=0.5.0; extra == "all"
Requires-Dist: ipython-genutils>=0.1.0; extra == "all"
Requires-Dist: mkdocs-jupyter>=0.20.0; extra == "all"
Requires-Dist: nbconvert>=6.4.2; extra == "all"
Requires-Dist: numpydoc>=1.2; extra == "all"
Requires-Dist: spacy>=3.2.2; extra == "all"
Requires-Dist: jinja2>=3.0.3; extra == "all"
Requires-Dist: dominate; extra == "all"
Requires-Dist: jupyter-client; extra == "all"
Requires-Dist: mkdocs-charts-plugin; extra == "all"
Requires-Dist: python-slugify; extra == "all"
Requires-Dist: watermark==2.3.1; extra == "all"
Provides-Extra: dev
Requires-Dist: scikit-learn~=1.5.0; extra == "dev"
Requires-Dist: torch~=2.2.2; extra == "dev"
Requires-Dist: pandas~=2.2.2; extra == "dev"
Requires-Dist: numpy~=1.26.4; extra == "dev"
Requires-Dist: river~=0.21.2; extra == "dev"
Requires-Dist: scipy~=1.13.0; extra == "dev"
Requires-Dist: tqdm~=4.66.5; extra == "dev"
Requires-Dist: ordered-set~=4.1.0; extra == "dev"
Requires-Dist: torchviz~=0.0.2; extra == "dev"
Requires-Dist: graphviz>=0.20.3; extra == "dev"
Requires-Dist: matplotlib>=3.9.2; extra == "dev"
Requires-Dist: mypy>=1.11.1; extra == "dev"
Requires-Dist: pre-commit>=3.8.0; extra == "dev"
Requires-Dist: pytest>=8.3.2; extra == "dev"
Requires-Dist: pytest-cov>=5.0.0; extra == "dev"
Requires-Dist: black>=24.8.0; extra == "dev"
Requires-Dist: flake8>=7.1.1; extra == "dev"
Requires-Dist: isort>=5.13.2; extra == "dev"
Requires-Dist: jupyter>=1.0.0; extra == "dev"
Requires-Dist: pyupgrade==3.17.0; extra == "dev"
Provides-Extra: docs
Requires-Dist: scikit-learn~=1.5.0; extra == "docs"
Requires-Dist: torch~=2.2.2; extra == "docs"
Requires-Dist: pandas~=2.2.2; extra == "docs"
Requires-Dist: numpy~=1.26.4; extra == "docs"
Requires-Dist: river~=0.21.2; extra == "docs"
Requires-Dist: scipy~=1.13.0; extra == "docs"
Requires-Dist: tqdm~=4.66.5; extra == "docs"
Requires-Dist: ordered-set~=4.1.0; extra == "docs"
Requires-Dist: torchviz~=0.0.2; extra == "docs"
Requires-Dist: flask>=2.0.2; extra == "docs"
Requires-Dist: ipykernel>=6.9.0; extra == "docs"
Requires-Dist: mike>=0.5.3; extra == "docs"
Requires-Dist: mkdocs>=1.2.3; extra == "docs"
Requires-Dist: mkdocs-awesome-pages-plugin>=2.7.0; extra == "docs"
Requires-Dist: mkdocs-gen-files>=0.3.5; extra == "docs"
Requires-Dist: mkdocs-charts-plugin>=0.0.8; extra == "docs"
Requires-Dist: mkdocs-literate-nav>=0.4.1; extra == "docs"
Requires-Dist: mkdocs-material>=8.1.11; extra == "docs"
Requires-Dist: mkdocstrings[python]>=0.19.0; extra == "docs"
Requires-Dist: pytkdocs[numpy-style]>=0.5.0; extra == "docs"
Requires-Dist: ipython-genutils>=0.1.0; extra == "docs"
Requires-Dist: mkdocs-jupyter>=0.20.0; extra == "docs"
Requires-Dist: nbconvert>=6.4.2; extra == "docs"
Requires-Dist: numpydoc>=1.2; extra == "docs"
Requires-Dist: spacy>=3.2.2; extra == "docs"
Requires-Dist: jinja2>=3.0.3; extra == "docs"
Requires-Dist: dominate; extra == "docs"
Requires-Dist: jupyter-client; extra == "docs"
Requires-Dist: mkdocs-charts-plugin; extra == "docs"
Requires-Dist: python-slugify; extra == "docs"
Requires-Dist: watermark==2.3.1; extra == "docs"


<p align="center">
  <img height="150px" src="https://raw.githubusercontent.com/online-ml/deep-river/master/docs/img/logo.png" alt="incremental dl logo">
</p>
<p align="center">
    <img alt="PyPI" src="https://img.shields.io/pypi/v/deep-river">
    <a href="https://codecov.io/gh/online-ml/deep-river" > 
        <img src="https://codecov.io/gh/online-ml/deep-river/branch/master/graph/badge.svg?token=ZKUIISZAYA"/> 
    </a>
    <img alt="PyPI - Downloads" src="https://img.shields.io/pypi/dm/deep-river">
    <img alt="GitHub" src="https://img.shields.io/github/license/online-ml/deep-river">
    <a href="https://joss.theoj.org/papers/6a76784f55e8b041d71a7fa776eb386a"><img src="https://joss.theoj.org/papers/6a76784f55e8b041d71a7fa776eb386a/status.svg"></a>
</p>
<p align="center">
    deep-river is a Python library for online deep learning.
    deep-river's ambition is to enable <a href="https://www.wikiwand.com/en/Online_machine_learning">online machine learning</a> for neural networks.
    It combines the <a href="https://www.riverml.xyz">river</a> API with the capabilities of designing neural networks based on <a href="https://pytorch.org">PyTorch</a>.
</p>

## ğŸ“š [Documentation](https://online-ml.github.io/deep-river/)
The [documentation](https://online-ml.github.io/deep-river/) contains an overview of all features of this repository as well as the repository's full features list. In each of these, the git repo reference is listed in a section that shows examples of the features and functionality.

## ğŸ’ˆ Installation

```shell
pip install deep-river
```
or
```shell
pip install "river[deep]"
```
You can install the latest development version from GitHub as so:

```shell
pip install https://github.com/online-ml/deep-river/archive/refs/heads/master.zip
```

## ğŸ« Quickstart

We build the development of neural networks on top of the <a href="https://www.riverml.xyz">river API</a> and refer to the rivers design principles.
The following example creates a simple MLP architecture based on PyTorch and incrementally predicts and trains on the website phishing dataset.
For further examples check out the <a href="https://online-ml.github.io/deep-river">Documentation</a>.

### Classification

```python
>>> from river import metrics, datasets, preprocessing, compose
>>> from deep_river import classification
>>> from torch import nn
>>> from torch import optim
>>> from torch import manual_seed

>>> _ = manual_seed(42)

>>> class MyModule(nn.Module):
...     def __init__(self, n_features):
...         super(MyModule, self).__init__()
...         self.dense0 = nn.Linear(n_features, 5)
...         self.nonlin = nn.ReLU()
...         self.dense1 = nn.Linear(5, 2)
...         self.softmax = nn.Softmax(dim=-1)
...
...     def forward(self, X, **kwargs):
...         X = self.nonlin(self.dense0(X))
...         X = self.nonlin(self.dense1(X))
...         X = self.softmax(X)
...         return X

>>> model_pipeline = compose.Pipeline(
...     preprocessing.StandardScaler(),
...     classification.Classifier(module=MyModule, loss_fn='binary_cross_entropy', optimizer_fn='adam')
... )

>>> dataset = datasets.Phishing()
>>> metric = metrics.Accuracy()

>>> for x, y in dataset:
...     y_pred = model_pipeline.predict_one(x)  # make a prediction
...     metric.update(y, y_pred)  # update the metric
...     model_pipeline.learn_one(x, y)  # make the model learn
>>> print(f"Accuracy: {metric.get():.4f}")
Accuracy: 0.7264

```
### Multi Target Regression 
```python
>>> from river import evaluate, compose
>>> from river import metrics
>>> from river import preprocessing
>>> from river import stream
>>> from sklearn import datasets
>>> from torch import nn
>>> from deep_river.regression.multioutput import MultiTargetRegressor

>>> class MyModule(nn.Module):
...     def __init__(self, n_features):
...         super(MyModule, self).__init__()
...         self.dense0 = nn.Linear(n_features, 3)
...
...     def forward(self, X, **kwargs):
...         X = self.dense0(X)
...         return X

>>> dataset = stream.iter_sklearn_dataset(
...         dataset=datasets.load_linnerud(),
...         shuffle=True,
...         seed=42
...     )
>>> model = compose.Pipeline(
...     preprocessing.StandardScaler(),
...     MultiTargetRegressor(
...         module=MyModule,
...         loss_fn='mse',
...         lr=0.3,
...         optimizer_fn='sgd',
...     ))
>>> metric = metrics.multioutput.MicroAverage(metrics.MAE())
>>> ev = evaluate.progressive_val_score(dataset, model, metric)
>>> print(f"MicroAverage(MAE): {metric.get():.2f}")
MicroAverage(MAE): 34.31

```

### Anomaly Detection

```python
>>> from deep_river.anomaly import Autoencoder
>>> from river import metrics
>>> from river.datasets import CreditCard
>>> from torch import nn
>>> import math
>>> from river.compose import Pipeline
>>> from river.preprocessing import MinMaxScaler

>>> dataset = CreditCard().take(5000)
>>> metric = metrics.ROCAUC(n_thresholds=50)

>>> class MyAutoEncoder(nn.Module):
...     def __init__(self, n_features, latent_dim=3):
...         super(MyAutoEncoder, self).__init__()
...         self.linear1 = nn.Linear(n_features, latent_dim)
...         self.nonlin = nn.LeakyReLU()
...         self.linear2 = nn.Linear(latent_dim, n_features)
...         self.sigmoid = nn.Sigmoid()
...
...     def forward(self, X, **kwargs):
...         X = self.linear1(X)
...         X = self.nonlin(X)
...         X = self.linear2(X)
...         return self.sigmoid(X)

>>> ae = Autoencoder(module=MyAutoEncoder, lr=0.005)
>>> scaler = MinMaxScaler()
>>> model = Pipeline(scaler, ae)

>>> for x, y in dataset:
...     score = model.score_one(x)
...     model.learn_one(x=x)
...     metric.update(y, score)
...
>>> print(f"ROCAUC: {metric.get():.4f}")
ROCAUC: 0.7812

```

## ğŸ« Affiliations

<p align="center">
    <img src="https://upload.wikimedia.org/wikipedia/de/thumb/4/44/Fzi_logo.svg/1200px-Fzi_logo.svg.png?raw=true" alt="FZI Logo" height="200"/>
</p>

<p align="center">
    <img src="https://lieferbotnet.de/wp-content/uploads/2022/09/LieferBotNet-Logo.png?raw=true" alt="Lieferbot net" height="200"/>
</p>
