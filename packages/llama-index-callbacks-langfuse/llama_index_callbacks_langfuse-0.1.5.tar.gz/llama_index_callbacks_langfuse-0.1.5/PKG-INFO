Metadata-Version: 2.1
Name: llama-index-callbacks-langfuse
Version: 0.1.5
Summary: llama-index callbacks langfuse integration
License: MIT
Author: Your Name
Author-email: you@example.com
Requires-Python: >=3.8.1,<4.0
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Dist: langfuse (>=2.21.2,<3.0.0)
Requires-Dist: llama-index-core (>=0.10.8,<0.11.0)
Description-Content-Type: text/markdown

# LlamaIndex Callbacks Integration: Langfuse

[Langfuse](https://langfuse.com/docs) is an open source LLM engineering platform to help teams collaboratively debug, analyze and iterate on their LLM Applications. With the Langfuse integration, you can seamlessly track and monitor performance, traces, and metrics of your LlamaIndex application. Detailed traces of the LlamaIndex context augmentation and the LLM querying processes are captured and can be inspected directly in the Langfuse UI.

#### Usage Pattern

```python
import llama_index.core.instrumentation as inst
from llama_index.callbacks.langfuse import LangfuseSpanHandler

langfuse_span_handler = LangfuseSpanHandler(
    public_key="<Your public key>",
    secret_key="<Your secret key>",
    host="<Host URL>",
)
dispatcher = inst.get_dispatcher()
dispatcher.add_span_handler(langfuse_span_handler)
```

![langfuse-tracing](https://static.langfuse.com/llamaindex-langfuse-docs.gif)

