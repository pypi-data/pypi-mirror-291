Metadata-Version: 2.1
Name: parsera-pieces
Version: 0.0.5
Summary: Fork of the original Parsera Lightweight library for scraping web-sites with Pieces QGPT LLM
Home-page: https://github.com/pieces-app/parsera-pieces
Author: Shivay at Pieces
Author-email: shivay@pieces.app
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: GNU General Public License v2 or later (GPLv2+)
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: langchain (>=0.2.6)
Requires-Dist: langchain-openai (>=0.1.8)
Requires-Dist: playwright (>=1.44.0)
Requires-Dist: playwright-stealth (>=1.0.6)
Requires-Dist: markdownify (>=0.12.1)
Requires-Dist: pieces-copilot-sdk (>=0.5.0)
Requires-Dist: parsera (>=0.1.3)

# ðŸ“¦ Parsera with Pieces

Fork of Parsera - Lightweight Python library for scraping websites with LLMs, specifically using Pieces QGPT endpoint.  

## Why Parsera?
Because it's simple and lightweight, with minimal token use which boosts speed and reduces expenses.

## Installation

```shell
pip install parsera-pieces
playwright install
```

## Basic usage

You can do this from python with:
```python
from parsera_pieces import Parsera

async def main():
       url = "https://code.pieces.app/blog"
       elements = {
           "Blog Title": "Title of the blog",
           "Blog Author": "Author of the specific blog post",
           "Published Date": "Date when the project was published",
       }

       scraper = Parsera(None)
       result = await scraper.arun(url=url, elements=elements)
       print(result)

if __name__ == "__main__":
       import asyncio
       asyncio.run(main())
```
