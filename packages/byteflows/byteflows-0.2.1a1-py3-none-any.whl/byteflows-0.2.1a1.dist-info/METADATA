Metadata-Version: 2.1
Name: byteflows
Version: 0.2.1a1
Summary: Simple scrape as SELECT * FROM ANYTHING in network
Keywords: scraping,web scraping,asyncio,web crawler,api crawler,api scraping
Author-Email: Danchuk Ivan <ivan.s.danchuk@gmail.com>
Maintainer-Email: Danchuk Ivan <ivan.s.danchuk@gmail.com>
License: Apache 2.0
Classifier: Development Status :: 3 - Alpha
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Operating System :: Microsoft
Classifier: Operating System :: POSIX
Classifier: Programming Language :: Python :: 3 :: Only
Classifier: Topic :: Software Development :: Libraries
Project-URL: Documentation, https://danchukivan.github.io/byteflows/
Project-URL: Repository, https://github.com/DanchukIvan/byteflows.git
Requires-Python: >=3.11
Requires-Dist: aiohttp<4.0.0,>=3.8
Requires-Dist: aioitertools<1.0.0,>=0.11.0
Requires-Dist: asyncio
Requires-Dist: fsspec<2024.0.0,>=2023.12.2
Requires-Dist: more-itertools
Requires-Dist: regex<2024.0.0,>=2023.12.25
Requires-Dist: uvloop; platform_system == "Linux"
Requires-Dist: yarl<2.0.0,>=1.9.4
Requires-Dist: dateparser>=1.2.0
Requires-Dist: loguru>=0.7.2; extra == "log"
Requires-Dist: loguru-config>=0.1.0; extra == "log"
Provides-Extra: log
Description-Content-Type: text/markdown

<h1 align="center">
  <img src="https://raw.githubusercontent.com/DanchukIvan/byteflows/main/docs/icons/logo.png" alt="byteflows" width="200px">
  <br>
</h1>

# **Simple data workflows**

Byteflows is a microframework that makes it easier to retrieve information from APIs and regular websites.

Byteflows, unlike complex projects like Scrapy or simple libraries like BeautifulSoup, is extremely easy to use due to the unification of the information extraction process and at the same time has quite a wide range of functionality.

## **Why use Byteflows?**

* 🚀 Byteflows is built on top of asyncio and asynchronous libraries, which significantly speeds up your code in the context of I/O operations.

* 🔁 With Byteflows, there is no need to continuously customize the data scraping process. From project to project, you will have a single, transparent architecture.

* ![s3](https://raw.githubusercontent.com/DanchukIvan/byteflows/main/docs/img/amazons3.svg) ![kafka](https://raw.githubusercontent.com/DanchukIvan/byteflows/main/docs/img/apachekafka.svg) ![psql](https://raw.githubusercontent.com/DanchukIvan/byteflows/main/docs/img/postgresql.svg) ![clickhouse](https://raw.githubusercontent.com/DanchukIvan/byteflows/main/docs/img/clickhouse.svg) Byteflows allows you to route data to any backend: s3-like storage, database, network file system, broker/message bus, etc.

* ⚙️ Byteflows allows the user to choose what to do with the data: hold it in memory until a certain critical value accumulates, or immediately send it to the backend, perform pre-processing, or leave it as is.

## **Installation**

Installation is as simple as:

`
pip install byteflows
`

## **Dependencies**

>The list of core Byteflows dependencies is represented by the following libraries:
>
> * aiohttp
> * aioitertools
> * fsspec
> * more-itertools
> * regex
> * uvloop (for Unix platforms)
> * yarl
> * dateparser

## **More information about the project**

You can learn more about Byteflows in the [project documentation](https://danchukivan.github.io/Byteflows/), including the API and Tutorial sections. Changes can be monitored in the Changelog section.

## **Project status**

Byteflows is currently a deep alpha project with an unstable API and limited functionality. Its use in production is **strictly not recommended**.
